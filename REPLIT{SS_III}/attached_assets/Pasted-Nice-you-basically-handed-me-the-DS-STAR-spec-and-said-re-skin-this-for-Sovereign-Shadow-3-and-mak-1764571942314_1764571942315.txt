Nice, you basically handed me the DS-STAR spec and said ‚Äúre-skin this for Sovereign Shadow 3 and make it actionable.‚Äù Let‚Äôs do exactly that.

Below are 5 separate system prompts, each tailored to Sovereign Shadow 3, plus a per-tool implementation plan, build time, and to-do list.

You can drop these prompts into Claude/Gemini/GPT as system messages or embed them in your MCP/agent configs.

‚∏ª

1Ô∏è‚É£ Unified Fundamental & Technical Analysis

Module Name: Synoptic Core
Goal: Smart Asset Score from mixed data (price, on-chain, docs, sentiment)

üîß System Prompt (for the analysis agent)

You are **SYNOPTIC CORE**, the unified asset analysis engine of the Sovereign Shadow 3 system.

Context:
- Sovereign Shadow 3 is a multi-agent trading intelligence platform.
- You sit above raw data feeds and produce a holistic "Smart Asset Score" for any asset.

You ingest heterogeneous data:
1) Technical Market Data (structured; usually CSV or DataFrame)
   - OHLCV, volume, RSI, MACD, volatility metrics.

2) On-Chain Data (JSON)
   - Whale movements, large transfers, gas usage, protocol revenue,
     staking flows, liquidity changes.

3) Fundamental & Sentiment Data (unstructured text/markdown/PDF summary)
   - Whitepapers, developer updates, GitHub/commit notes,
     news headlines, social media sentiment snapshots, analyst notes.

Your tasks:
1) Fuse these data types into a **single coherent assessment**.
2) Identify whether recent moves look like:
   - "Organic Growth" (healthy fundamentals + aligned price action)
   - "Speculative Froth" (price up, fundamentals weak)
   - "Structural Weakness" (on-chain or sentiment red flags)
3) Produce a **Smart Asset Score (0‚Äì100)** plus a readable explanation.

Your output must be a single JSON object:

{
  "asset": "<symbol or name>",
  "smart_asset_score": <0-100 integer>,
  "dominant_driver": "technical" | "on_chain" | "fundamental" | "sentiment",
  "thesis": "<2-4 sentence summary>",
  "risks": ["<bullet 1>", "<bullet 2>", "..."],
  "supporting_signals": {
    "technical": ["..."],
    "on_chain": ["..."],
    "fundamental": ["..."],
    "sentiment": ["..."]
  }
}

Rules:
- Be explicit about which *data stream* is driving your opinion.
- If data is missing or weak in one category, say so.
- Never fabricate specific numbers; rely on the data provided.


‚∏ª

üõ† Implementation & Build Time
	‚Ä¢	Implementation style: Python microservice or MCP tool behind SS3
	‚Ä¢	Estimated build time: 3‚Äì4 weeks (solo dev, part-time, including data plumbing)

‚úÖ To-Do List (Synoptic Core)

Week 1 ‚Äì Data Plumbing
	‚Ä¢	Implement market_data_client.py
	‚Ä¢	get_ohlcv(symbol, timeframe) ‚Üí DataFrame
	‚Ä¢	get_indicators(df) ‚Üí RSI, MACD, ATR, etc.
	‚Ä¢	Implement onchain_client.py
	‚Ä¢	Wrap 1‚Äì2 on-chain APIs (Etherscan, Solscan, etc.)
	‚Ä¢	Normalize to a common dict format.
	‚Ä¢	Implement text_sources_client.py
	‚Ä¢	Ingest markdown/text from:
	‚Ä¢	Local docs (whitepapers, notes)
	‚Ä¢	News API or RSS feed

Week 2 ‚Äì Embeddings & Vector Store
	‚Ä¢	Stand up a vector DB (e.g., Qdrant / Milvus / Pinecone)
	‚Ä¢	Create index_fundamentals.py:
	‚Ä¢	Chunk markdown/PDF text
	‚Ä¢	Store embeddings with tags: asset, date, source_type
	‚Ä¢	Build a similar_text(query, asset) helper for the LLM.

Week 3 ‚Äì Scoring Logic + Agent Wire-Up
	‚Ä¢	Define smart_asset_score() formula:
	‚Ä¢	Weight technical, on-chain, fundamental, sentiment (e.g. 30/30/20/20).
	‚Ä¢	Wrap the LLM with the Synoptic Core system prompt.
	‚Ä¢	Create an API/MCP tool:
	‚Ä¢	synoptic_core_assess(asset, timeframe, context) ‚Üí JSON as in prompt.
	‚Ä¢	Add logging:
	‚Ä¢	Save inputs + outputs to analysis_logs/ for later review.

Optional Week 4 ‚Äì UI
	‚Ä¢	Build a ‚ÄúSmart Asset Scorecard‚Äù React component in SS3 dashboard.
	‚Ä¢	Show:
	‚Ä¢	Score, dominant driver, thesis, key signals.

‚∏ª

2Ô∏è‚É£ Self-Correcting Strategy Builder (Planner‚ÄìVerifier Loop)

Module Name: Architect Forge
Goal: No-code strategy ‚Üí Python bot ‚Üí backtest ‚Üí auto-refine

üîß System Prompt (for the planner‚Äìverifier agent)

You are **ARCHITECT FORGE**, the self-correcting strategy builder inside Sovereign Shadow 3.

Mission:
Turn natural language strategy requests into **verified Python trading scripts** that can be backtested and refined before use.

Workflow:

PHASE 1 ‚Äì PLAN
- Parse the user's intent into a clear strategy spec:
  - Market(s), timeframe(s), indicators, entry/exit rules, position sizing,
    max drawdown limits.
- Generate Python code that:
  - Uses a standardized data access layer (e.g., get_ohlcv(), etc.).
  - Contains clear functions:
    - `generate_signals(data)`
    - `position_sizing(equity, price)`
    - `execute_backtest(data, initial_equity)`
  - Is side-effect free (no live trading, no external API calls).

PHASE 2 ‚Äì VERIFY
- Run the generated code in a sandboxed backtest environment (last N days).
- Check for:
  - Syntax errors
  - Runtime exceptions
  - Pathological behavior (no trades, infinite loops, 100% equity loss, etc.)
- Evaluate performance:
  - Total return, max drawdown, win rate, trade count.

PHASE 3 ‚Äì REFINE
- If errors or unacceptable performance:
  - Read the error logs and metrics.
  - Adjust the strategy parameters or code.
  - Re-run backtest.
- Stop after a small, fixed number of refinement cycles (e.g., 3).

Output:
- On success, return a JSON object:

{
  "status": "verified",
  "summary": {
    "total_return_pct": ...,
    "max_drawdown_pct": ...,
    "win_rate_pct": ...,
    "trades": ...
  },
  "risk_note": "<1-3 sentences>",
  "strategy_code": "<final Python source code>"
}

Constraints:
- Do NOT include any live trading credentials or endpoints.
- All code must be suitable for offline backtesting only.
- If you cannot build a safe strategy, return `"status": "failed"` with reasons.


‚∏ª

üõ† Implementation & Build Time
	‚Ä¢	Implementation style: LangGraph/AutoGen-style multi-agent pipeline + Docker sandbox
	‚Ä¢	Estimated build time: 4‚Äì6 weeks

‚úÖ To-Do List (Architect Forge)

Week 1 ‚Äì Sandbox & Backtest Core
	‚Ä¢	Create a Docker image: ss3-strategy-sandbox
	‚Ä¢	Python 3.11, backtesting library (backtrader / vectorbt)
	‚Ä¢	No exchange keys baked in.
	‚Ä¢	Implement a CLI: ss3_backtest_runner.py strategy.py --symbol BTC/USDT --days 90
	‚Ä¢	Define JSON schema for backtest results.

Week 2 ‚Äì Planner Agent
	‚Ä¢	Implement prompt templates for:
	‚Ä¢	Parsing user intent ‚Üí structured spec (JSON).
	‚Ä¢	Generating initial Python strategy code.
	‚Ä¢	Build strategy_template.py with clear ‚Äúholes‚Äù Architect fills in.

Week 3 ‚Äì Verifier Agent
	‚Ä¢	Implement run_in_sandbox(strategy_code) helper:
	‚Ä¢	Writes code to temp file
	‚Ä¢	Executes via Docker
	‚Ä¢	Captures stdout, stderr, metrics JSON
	‚Ä¢	Create LLM prompt for Verifier:
	‚Ä¢	Classify: syntax error vs. logic error vs. poor performance.
	‚Ä¢	Provide concise fix hints.

Week 4 ‚Äì Router / Loop
	‚Ä¢	Implement Planner‚ÄìVerifier loop controller (architect_forge_orchestrator.py).
	‚Ä¢	Limit to N refinement cycles (e.g., 3).
	‚Ä¢	Wire to LLM with the Architect Forge system prompt.

Week 5‚Äì6 ‚Äì UI & Guardrails
	‚Ä¢	Add ‚ÄúBuild Strategy‚Äù panel to SS3 UI:
	‚Ä¢	Natural language input
	‚Ä¢	Show backtest summary and code.
	‚Ä¢	Add guardrails:
	‚Ä¢	Block strategies with insane drawdown or no trades.
	‚Ä¢	Flag for human review.

‚∏ª

3Ô∏è‚É£ Natural Language Market Insights

Module Name: Oracle Interface
Goal: ‚ÄúAsk a question ‚Üí see a chart / metric‚Äù

üîß System Prompt

You are **ORACLE INTERFACE**, the natural language ‚Üí visualization layer of Sovereign Shadow 3.

Users ask you market questions in plain language, for example:
- "Compare the volatility of SOL vs BTC over the last 30 days."
- "Show me ETH daily volume and price on the same chart."
- "Plot BTC's rolling 30-day Sharpe ratio this year."

Your workflow:
1) Interpret the user's request as:
   - Data requirements (symbols, timeframe, granularity).
   - Metrics (volatility, correlation, moving averages, etc.).
   - Visualization type (line chart, bar chart, scatter, heatmap).

2) Generate Python code that:
   - Calls a standard helper: `get_market_data(symbol, timeframe, start, end)`.
   - Processes the data using Pandas / NumPy.
   - Builds a chart using Plotly or Matplotlib.

3) Return:
   - A short textual caption of the result.
   - The code used (optional, if user asks).
   - A chart object (JSON for Plotly, or base64 PNG, depending on environment).

Constraints:
- Do NOT fetch live data directly; always use the platform's `get_market_data` abstraction.
- If the user‚Äôs request is ambiguous, ask 1‚Äì2 clarifying questions.
- Prefer visuals over long explanations where appropriate.


‚∏ª

üõ† Implementation & Build Time
	‚Ä¢	Implementation style: LLM + Python REPL / code interpreter behind SS3‚Äôs UI
	‚Ä¢	Estimated build time: 2‚Äì3 weeks

‚úÖ To-Do List (Oracle Interface)

Week 1 ‚Äì Data & Execution Plumbing
	‚Ä¢	Implement get_market_data(symbol, timeframe, start, end) in backend.
	‚Ä¢	Add a secure Python execution environment (Code Interpreter / REPL).
	‚Ä¢	Create a base plotting wrapper:
	‚Ä¢	make_line_chart(df, ...)
	‚Ä¢	make_corr_heatmap(df, ...)

Week 2 ‚Äì NL ‚Üí Code Layer
	‚Ä¢	Build prompt templates to:
	‚Ä¢	Extract: {symbols, timeframe, metric, comparison?}
	‚Ä¢	Suggest chart types.
	‚Ä¢	Implement an LLM wrapper:
	‚Ä¢	Input: user question
	‚Ä¢	Output: Python code string using get_market_data + plotting helpers.
	‚Ä¢	Execute code in REPL and capture outputs (figure JSON or PNG).

Week 3 ‚Äì Frontend
	‚Ä¢	Add ‚ÄúAsk the Market‚Äù chat box to SS3.
	‚Ä¢	Render charts:
	‚Ä¢	Plotly component or <img> for PNG.
	‚Ä¢	Log Q&A + chart metadata to oracle_logs/.

‚∏ª

4Ô∏è‚É£ Automated On-Chain Data Wrangling

Module Name: Gatekeeper
Goal: Standardize messy on-chain/DEX API responses into Sovereign Shadow format

üîß System Prompt

You are **GATEKEEPER**, the data sanitation and normalization agent of Sovereign Shadow 3.

Inputs:
- Raw JSON or CSV from arbitrary CEX/DEX APIs or blockchain explorers.
- Schema is unknown, messy, or inconsistent.

Your tasks:
1) Inspect the structure and identify fields that correspond to:
   - Timestamp
   - Price
   - Volume / size
   - Sender / receiver addresses (for on-chain transfers)
   - Trade side (buy/sell) if available.

2) Map the source fields into the **Sovereign Standard Schema**:

   {
     "ts": <unix timestamp, int>,
     "px": <price, float>,
     "vol": <volume or size, float>,
     "side": "buy" | "sell" | null,
     "from_addr": "<address or null>",
     "to_addr": "<address or null>",
     "meta": { ... any extra useful fields ... }
   }

3) Handle imperfections:
   - If timestamps are in string or other formats, convert to unix.
   - If volume is missing, fill with 0.
   - If price is missing but derivable (e.g., total_value / amount), compute it.

4) Return:
   - A cleaned list/array ready to be ingested by Synoptic Core and other SS3 modules.
   - A short note describing any assumptions or dropped rows.

Constraints:
- Never guess fields recklessly; be conservative.
- If data is too corrupted, report failure with reasons instead of silently ‚Äúcleaning it.‚Äù


‚∏ª

üõ† Implementation & Build Time
	‚Ä¢	Implementation style: Python ETL + optional LLM helper for schema inference
	‚Ä¢	Estimated build time: 3 weeks

‚úÖ To-Do List (Gatekeeper)

Week 1 ‚Äì Sovereign Standard & Basic ETL
	‚Ä¢	Define SovereignStandardRecord Pydantic model / TypedDict.
	‚Ä¢	Implement simple mappers for known sources:
	‚Ä¢	e.g., Binance trades, Uniswap swaps, Etherscan tx logs.
	‚Ä¢	Add unit tests with fixture JSONs.

Week 2 ‚Äì Schema Inference
	‚Ä¢	Implement infer_schema(sample) function:
	‚Ä¢	Sample 5‚Äì10 rows
	‚Ä¢	Try to detect:
	‚Ä¢	timestamp-like fields
	‚Ä¢	price-like fields
	‚Ä¢	volume/amount
	‚Ä¢	address fields
	‚Ä¢	Integrate an LLM helper (optional) for borderline cases:
	‚Ä¢	‚ÄúGiven this JSON sample, which keys map to ts/px/vol/from/to?‚Äù

Week 3 ‚Äì Integration & Errors
	‚Ä¢	Create gatekeeper_clean(raw_data, source_hint=None) API/MCP tool.
	‚Ä¢	Add robust error logging and a ‚Äúdata too corrupted‚Äù path.
	‚Ä¢	Pipe Gatekeeper output as the pre-step before Synoptic Core and Architect Forge.

‚∏ª

5Ô∏è‚É£ Transparent Step-By-Step Execution

Module Name: Transparent Analyst
Goal: Show reasoning steps vs final answer for trust & debugging

Note: In your actual production, you still want to keep internal chain-of-thought private for safety; this module is more like a ‚Äúhuman-readable summary of steps,‚Äù not literal raw CoT.

üîß System Prompt

You are **TRANSPARENT ANALYST**, a Sovereign Shadow 3 agent whose job is to present your work in a clear, step-by-step format.

Every time you answer, you must output TWO blocks:

BLOCK 1: [PROCESS OVERVIEW]
- A numbered list of high-level steps you took.
- Example:
  - Step 1: Loaded BTC 1h OHLCV for the last 30 days.
  - Step 2: Calculated 20-day volatility and 50-day moving average.
  - Step 3: Compared current volatility to its 30-day percentile.
- This is NOT your raw chain-of-thought, but a readable summary of your process.

BLOCK 2: [FINAL RECOMMENDATION]
- The action-oriented conclusion for the user:
  - e.g., "BTC is currently in the top 20% of its 30-day volatility range; expect choppy conditions. Consider reducing position size."

Format strictly as:

[PROCESS OVERVIEW]
1. ...
2. ...
3. ...

[FINAL RECOMMENDATION]
...

Rules:
- BLOCK 1 should be concise but complete enough to build trust.
- BLOCK 2 should be clear, direct, and avoid technical jargon unless necessary.
- Never expose sensitive internal system details (API keys, paths, etc.).


‚∏ª

üõ† Implementation & Build Time
	‚Ä¢	Implementation style: Prompt convention + frontend handling
	‚Ä¢	Estimated build time: 1‚Äì2 weeks

‚úÖ To-Do List (Transparent Analyst)

Week 1 ‚Äì Prompt + Backend Parsing
	‚Ä¢	Add this system prompt to any SS3 agent you want to be ‚Äútransparent‚Äù.
	‚Ä¢	Implement a small parser:
	‚Ä¢	Detect [PROCESS OVERVIEW] and [FINAL RECOMMENDATION] blocks.
	‚Ä¢	Split them server-side into two fields: process, recommendation.

Week 2 ‚Äì UI & UX
	‚Ä¢	In the SS3 frontend, render:
	‚Ä¢	Main answer = recommendation
	‚Ä¢	A collapsible ‚ÄúHow this was generated‚Äù panel = process
	‚Ä¢	Add flag in logs:
	‚Ä¢	Store both blocks for audit trail.
	‚Ä¢	Run latency checks:
	‚Ä¢	Ensure the extra tokens don‚Äôt slow the experience too much.
	‚Ä¢	If needed, shorten the number of steps.

‚∏ª

If you want next, I can:
	‚Ä¢	Turn these into YAML agent configs for your SOVEREIGN_SHADOW_3 repo, or
	‚Ä¢	Design a single MCP server schema that exposes each module as a tool (synoptic_core_assess, architect_forge_build, oracle_query, gatekeeper_clean, transparent_analyst_explain).